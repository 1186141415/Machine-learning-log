### 均衡偏差与方差

当讨论线性回归的时候，我们讨论是否训练如
$$
y=\theta_0+\theta_1x
$$
的简单模型或者更复杂些的多项式模型
$$
y=\theta_0+\theta_1x+\cdots+\theta_5x
$$
可以看下图：

![image-20200906223657728](/Users/limuyuan/Library/Application Support/typora-user-images/image-20200906223657728.png)

像最右面那样训练5阶多项式的模型并不是一个好的模型。尽管这个5阶的多项式可以很好的在训练集中从x(代表房屋面积)预测y(代表房价)，但是我们实际上并不希望模型只在训练集上表现良好。假设的泛化误差是他的预测错误。

上面最左和最右面的模型都具有特别大的泛化误差，然而他们所面临的问题却不一样，如果y和x的关系不是

线性（一阶）的，即便我们我们用特别大的数据量去训练模型，我们仍然很精确难捕捉到数据之间存在的结构关系。非正式的，我们定义一个模型的偏差为预测的泛化误差，即便我们拥有非常大的数据量去训练模型，因此，对于上述问题，线性模型，面临非常大的偏差，并且不足以捕捉到数据中的结构关系。



在偏差之外，还有泛化误差的另外一个因素。由模型在训练过程中的偏差组成。尤其像最右面的图一样，训练一个5阶多项式，我们会获得一个非常好的对应关系，在我们小而且有限的训练集上，但是这种关系在更广的范围内反映x和y的关系表现并不良好。这就是说，在训练集中，我们碰巧在这里得到一个比平均值更贵一点的房子，在那里碰到一个一个比平均更便宜的房子等等。通过训练这个在训练集中虚假的关系，我们可能获得一个具有很大泛化误差的模型，在这种情况下，我们就说我们的模型具有特别大的方差。



如果我们的模型特别简单，我们就说我们的模型具有偏差，如果模型特别复杂诸如特别多的参数，我们就说我们的模型具有特别大的方差。在上面的问题中，训练一个二次的模型表现比一次和五次的好。



## 先验

​        在这套笔记中，我们开始涉足学习理论。除了本身有趣和启发性的讨论外，本讨论还将帮助我们磨练直觉并得出有关如何在不同环境中最佳应用学习算法的经验法则。我们还将寻求回答一些问题：首先，我们可以正式进行刚刚讨论的偏差/方差折衷吗？这最终也将使我们谈论模型选择方法，例如，模型选择方法可以自动确定适合训练集的阶次多项式。其次，在机器学习中，我们真正关心的是泛化错误，但是大多数学习算法都将其模型拟合到训练集中。为什么在训练集上做得好能告诉我们有关泛化错误的任何信息？具体来说，我们可以将训练集上的错误与泛化错误联系起来吗？第三，也是最后，我们是否有条件可以实际证明学习算法会很好地工作？

​        我们从两个简单但非常有用的引理开始。

##### 引理（联合边界）

让A<sub>1</sub>,A<sub>2</sub>,.....,A<sub>k</sub>,为k个不同的事件（可能不是独立的事件）
$$
P(A_1\cup\cdots\cup A_k)\leq P(A_1)+\cdots+p(A_k)
$$

##### 引理（霍夫丁不等式）

令Z<sub>1</sub>,.....,Z<sub>k</sub>为n个独立的且从伯努利（φ）分布得出的均匀分布（iid）随机变量。即
$$
P(Z_i=1)=\phi\\p(Z_i=0)=1-\phi
$$


设
$$
\hat\phi=(1/n)\sum_{i=1}^nZ_i
$$
为这些随机变量的均值并且使
$$
\gamma>0
$$
固定，那么我们就会获得：
$$
P(\mid\phi-\hat\phi\mid>\gamma)\leq2exp(-2\gamma^2n)
$$
以上的不等式在机器学习理论中被称为切诺夫边界，他的核心思想是在说，如果我们有n个贝努力随机变量的均值
$$
\hat\phi
$$
作为我们对
$$
\phi
$$
进行估计，那么当n越来越大时，我们的估计误差将会越来越小。

​        使用上面的两个方法，我们将会证明机器学习中最重要和最深刻的理论。

​        为了简化我们的阐述，我们将会将我们的关注点放到二分类问题（只有{1,0}标签的分类）。我们在这里所说的一切都会泛化到其他问题，包括回归和多类分类。

我们假设给定一个训练集，
$$
S=\{(x^{(i)},y^{(i)});i=1,...,n\}
$$
其中训练样本是从某个概率分布D得出的独立且分布均匀分布。

对于假设h，我们定义了训练误差（也称为经验风险或经验误差，在学习理论上）
$$
\hat\varepsilon=\frac12\sum_{i=1}^n1\{h(x^{(i)}\neq y^{(i)})\}
$$


这只是h分类错误的训练示例的一部分。什么时候我们想要明确说明
$$
\hat \varepsilon(h)
$$
对训练集S的依赖性，我们可能会将他写成
$$
\hat \varepsilon_s(h)
$$
我们还将泛化误差定义为
$$
\varepsilon(h)=P_(x,y)～D（h(x)\neq y）
$$
这是在说我们从分布D中获得新样本（x，y）时h错误分类它的概率。

​       注意，我们的训练数据来源于我们用来评估假设的分布D，有时也将其称为PAC假设之一。

> ​    PAC代表“可能近似正确”，这是一个框架和一组假设，在这些框架和假设下，可以证明学习理论上的许多结果。其中，最重要的假设是在相同分布上进行训练和测试，并假设独立绘制训练样本。

​      思考线性分类的设置，并且让
$$
h_{\theta}(x)=1\{\theta^Tx\ge0\}
$$
拟合参数
$$
\theta
$$
的合理方法是什么？

一种方法是尝试最小化训练误差，然后选择
$$
\hat\theta=arg\mathop{min}_\theta\hat \varepsilon(h_\theta)
$$
我们将此过程称为经验风险最小化（ERM），学习算法输出的假设结果为
$$
\hat h=h_{\hat \theta}
$$
我们将ERM视为最“基础”的学习算法，而我们将在这些笔记中重点介绍该算法。 （逻辑回归等算法也可以看作是经验风险最小化的近似值。）



在我们的学习理论研究中，从假设的特定参数化和诸如我们是否使用线性分类器之类的问题中抽象出来将很有用



在我们的学习理论研究中，从假设的特定参数化和诸如我们是否使用线性分类器之类的问题中抽象出来将很有用。我们将一个学习算法所考虑到的所有分类器构成的集合称为假设类
$$
\mathcal{H}
$$
对于定义域X是线性边界的分类器为：
$$
\mathcal{H}=\{h_\theta:h_\theta(x)=1\{\theta^T x\ \geq0 \},\theta \in \mathbb{R}^{d+1} \}
$$
最小化训练误差可以被表示为最小化假设类
$$
\mathcal{H}
$$
数学表示为
$$
\hat h=arg\mathop{min}_{h\in\mathcal H}\hat \varepsilon(h)
$$

### 当假设类H是无限的情况